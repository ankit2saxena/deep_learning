{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import face_recognition\n",
    "import moviepy.editor as mpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_width = 224\n",
    "sample_height = 224\n",
    "n_frames_from_video = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Code Run for one video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = \"_uNup91ZYw0.002.mp4\"\n",
    "video = cv2.VideoCapture(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_from_videos(video, n_random_frame):\n",
    "    count = 0\n",
    "    file_iter = 0\n",
    "    n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    random_frame = np.random.randint(1, n_frames, size = n_random_frame * 3)\n",
    "                      \n",
    "    while(video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        count += 1\n",
    "        if ret == True and file_iter < 5:\n",
    "            if count in random_frame:\n",
    "                \n",
    "                # flip the frame for randomness\n",
    "                random_flip = np.random.randint(-1, 2)\n",
    "                frame = cv2.flip(frame, random_flip)\n",
    "\n",
    "                recface = face_recognition.face_locations(frame)\n",
    "                \n",
    "                if len(recface) > 0:\n",
    "                    top, right, bottom, left = recface[0]\n",
    "                    \n",
    "                    width = right - left\n",
    "                    height = bottom - top\n",
    "                    center_X = (left + right) / 2\n",
    "                    center_Y = (top + bottom) / 2\n",
    "\n",
    "                    # to choose a window of 224 * 224\n",
    "                    top = int(center_Y - sample_height / 2)\n",
    "                    left = int(center_X - sample_width / 2)\n",
    "                    height = sample_height\n",
    "                    width = sample_width\n",
    "                    \n",
    "                    face_image = frame[top:(top + height), left:(left + width)]\n",
    "\n",
    "                    # write the flipped frame\n",
    "                    cv2.imwrite(\"frame%d.jpg\" % file_iter, face_image)\n",
    "                    #cv2.imshow('frame',face_image)\n",
    "                    file_iter += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if file_iter == n_random_frame:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_images_from_videos(video, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the path Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_video_path = \"Data/Videos/Training/\"\n",
    "training_input_labels_path = \"Data/training_gt.csv\"\n",
    "training_image_path = \"Data/Images/Training/\"\n",
    "training_output_labels_path = \"Data/training_final.csv\"\n",
    "\n",
    "test_video_path = \"Data/Videos/Test/\"\n",
    "tset_input_labels_path = \"Data/validation_gt.csv\"\n",
    "test_image_path = \"Data/Images/Test/\"\n",
    "test_output_labels_path = \"Data/test_final.csv\"\n",
    "\n",
    "validation_video_path = \"Data/Videos/Validation/\"\n",
    "validation_input_labels_path = \"Data/validation_gt.csv\"\n",
    "validation_image_path = \"Data/Images/Validation/\"\n",
    "validation_output_labels_path = \"Data/validation_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Data/Images\"):\n",
    "    os.mkdir(\"Data/Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Read the input label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_labels_data = pd.read_csv(training_input_labels_path)\n",
    "training_input_labels_columns = list(training_input_labels_data.columns.values)\n",
    "training_input_labels_columns.append(\"ImageName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>ValueExtraversion</th>\n",
       "      <th>ValueAgreeableness</th>\n",
       "      <th>ValueConscientiousness</th>\n",
       "      <th>ValueNeurotisicm</th>\n",
       "      <th>ValueOpenness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GQczMGrVgbc.001.mp4</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>0.703297</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-utrsarZeIY.004.mp4</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.436893</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3HA2W1s4oP8.001.mp4</td>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hM96SfN5_F4.004.mp4</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.359223</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SgzOYog1pH4.003.mp4</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.650485</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.477778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VideoName  ValueExtraversion  ValueAgreeableness  \\\n",
       "0  GQczMGrVgbc.001.mp4           0.570093            0.703297   \n",
       "1  -utrsarZeIY.004.mp4           0.523364            0.516484   \n",
       "2  3HA2W1s4oP8.001.mp4           0.401869            0.538462   \n",
       "3  hM96SfN5_F4.004.mp4           0.485981            0.637363   \n",
       "4  SgzOYog1pH4.003.mp4           0.532710            0.527473   \n",
       "\n",
       "   ValueConscientiousness  ValueNeurotisicm  ValueOpenness  \n",
       "0                0.640777          0.666667       0.544444  \n",
       "1                0.436893          0.333333       0.411111  \n",
       "2                0.427184          0.510417       0.388889  \n",
       "3                0.359223          0.458333       0.566667  \n",
       "4                0.650485          0.458333       0.477778  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_input_labels_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Create a List for the output label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_labels_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_output_labels_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Read the contents of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_video_filenames = os.listdir(training_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Create dataset of images from each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_from_videos(video, n_random_frames, target_dir, target_filename):\n",
    "    \n",
    "    np.random.seed(100)\n",
    "    \n",
    "    count = 0\n",
    "    file_iter = 0\n",
    "    n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    random_frame = np.random.randint(1, n_frames, size = n_random_frames * 2)\n",
    "    random_frame = np.sort(random_frame)\n",
    "    random_frame = np.unique(random_frame)\n",
    "                      \n",
    "    while(video.isOpened()):\n",
    "        ret, frame = video.read()\n",
    "        count += 1\n",
    "        if ret == True and file_iter < n_random_frames:\n",
    "            if count in random_frame:\n",
    "                \n",
    "                recface = face_recognition.face_locations(frame)\n",
    "                \n",
    "                if len(recface) > 0:\n",
    "                    top, right, bottom, left = recface[0]\n",
    "                    \n",
    "                    width = right - left\n",
    "                    height = bottom - top\n",
    "                    center_X = (left + right) / 2\n",
    "                    center_Y = (top + bottom) / 2\n",
    "\n",
    "                    # to choose a window of 224 * 224\n",
    "                    #top = int(center_Y - sample_height / 2)\n",
    "                    #left = int(center_X - sample_width / 2)\n",
    "                    #height = sample_height\n",
    "                    #width = sample_width\n",
    "                    \n",
    "                    if (top - 20) > 0:\n",
    "                        if (top - 40) > 0:\n",
    "                            top = top - 40\n",
    "                            height = height + 80\n",
    "                        else:\n",
    "                            top = top - 20\n",
    "                            height = height + 40\n",
    "                        \n",
    "                    if (left - 20) > 0:\n",
    "                        if (left - 40) > 0:\n",
    "                            left = left - 40\n",
    "                            width = width + 80\n",
    "                        else:\n",
    "                            left = left - 20\n",
    "                            width = width + 40\n",
    "                    \n",
    "                    if(top >=0 and left >= 0):\n",
    "                        face_image = frame[top:(top + height), left:(left + width)]\n",
    "\n",
    "                        # write the flipped frame\n",
    "                        if not os.path.exists(target_dir):\n",
    "                            os.mkdir(target_dir)\n",
    "                        face_image = cv2.resize(face_image, (sample_width, sample_height))\n",
    "                        \n",
    "                        # flip the frame for randomness\n",
    "                        #random_flip = np.random.randint(-1, 2)\n",
    "                        #face_image = cv2.flip(face_image, random_flip)\n",
    "\n",
    "                        cv2.imwrite(target_dir + target_filename + \"_%d.jpg\" % (file_iter+1), face_image)\n",
    "                        #cv2.imshow('frame',face_image)\n",
    "                        file_iter += 1\n",
    "                    else:\n",
    "                        print(\"Dimension less than zero for video: \", target_filename)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    if file_iter == n_random_frames:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputLabels(video_filenames, input_labels_data, video_path, image_path, n_frames, returnLabels):\n",
    "    output_labels_data = []\n",
    "    for curr_video_id in video_filenames:\n",
    "        # for train and validation:\n",
    "        if returnLabels:\n",
    "            if curr_video_id in input_labels_data[\"VideoName\"].values:\n",
    "                curr_video_data = input_labels_data[input_labels_data[\"VideoName\"] == curr_video_id]\n",
    "                curr_videoName = curr_video_data[\"VideoName\"].values[0]\n",
    "                curr_E = curr_video_data[\"ValueExtraversion\"].values[0]\n",
    "                curr_A = curr_video_data[\"ValueAgreeableness\"].values[0]\n",
    "                curr_C = curr_video_data[\"ValueConscientiousness\"].values[0]\n",
    "                curr_N = curr_video_data[\"ValueNeurotisicm\"].values[0]\n",
    "                curr_O = curr_video_data[\"ValueOpenness\"].values[0]\n",
    "                curr_frameName = curr_videoName[:-4]        \n",
    "\n",
    "                curr_video = cv2.VideoCapture(video_path + curr_videoName)\n",
    "\n",
    "                if (save_frames_from_videos(curr_video, n_frames, image_path, curr_frameName) == True):\n",
    "                    for i in range(0, n_frames):\n",
    "                        curr_ImageName = curr_frameName + \"_\" + str(i+1)+\".jpg\"\n",
    "                        output_labels_data.append([curr_videoName, curr_E, curr_A, curr_C, curr_N, curr_O, curr_ImageName])\n",
    "                else:\n",
    "                    print(\"Failed: \", curr_videoName)\n",
    "\n",
    "            else:\n",
    "                print(\"Video details not found in the input label file.\")\n",
    "                curr_video.release()\n",
    "        # for test:\n",
    "        else:\n",
    "            curr_frameName = curr_video_id[:-4]\n",
    "            curr_video = cv2.VideoCapture(video_path + curr_video_id)\n",
    "            save_frames_from_videos(curr_video, n_frames, image_path, curr_frameName)\n",
    "            \n",
    "    return output_labels_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed:  36NZ0sHWQFg.001.mp4\n",
      "Failed:  8eeZjC_bmtc.005.mp4\n",
      "Failed:  8mZZlnbmOYE.000.mp4\n",
      "Failed:  8mZZlnbmOYE.001.mp4\n",
      "Failed:  8mZZlnbmOYE.003.mp4\n",
      "Failed:  A0braVJH3Pw.000.mp4\n",
      "Failed:  aaDlp62qn60.002.mp4\n",
      "Failed:  Fe9_SVPd_5I.005.mp4\n",
      "Failed:  IwfA-squ7Oo.002.mp4\n",
      "Failed:  JIR4aPcyrn8.001.mp4\n",
      "Failed:  lNaZ4aJaiBU.000.mp4\n",
      "Failed:  NDBCrVvp0Vg.000.mp4\n",
      "Failed:  syTTeox8Yaw.003.mp4\n",
      "Failed:  TWKKCoT4FTc.001.mp4\n"
     ]
    }
   ],
   "source": [
    "n_frames_from_video = 5\n",
    "\n",
    "training_output_labels_data = getOutputLabels(training_video_filenames, training_input_labels_data, \n",
    "                                                training_video_path, training_image_path,\n",
    "                                                n_frames_from_video, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Create a DataFrame of the output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_labels_data = pd.DataFrame(training_output_labels_data, columns=training_input_labels_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>ValueExtraversion</th>\n",
       "      <th>ValueAgreeableness</th>\n",
       "      <th>ValueConscientiousness</th>\n",
       "      <th>ValueNeurotisicm</th>\n",
       "      <th>ValueOpenness</th>\n",
       "      <th>ImageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-2qsCrkXdWs.001_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-2qsCrkXdWs.001_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-2qsCrkXdWs.001_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-2qsCrkXdWs.001_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2qsCrkXdWs.001.mp4</td>\n",
       "      <td>0.476636</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>-2qsCrkXdWs.001_5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VideoName  ValueExtraversion  ValueAgreeableness  \\\n",
       "0  -2qsCrkXdWs.001.mp4           0.476636            0.593407   \n",
       "1  -2qsCrkXdWs.001.mp4           0.476636            0.593407   \n",
       "2  -2qsCrkXdWs.001.mp4           0.476636            0.593407   \n",
       "3  -2qsCrkXdWs.001.mp4           0.476636            0.593407   \n",
       "4  -2qsCrkXdWs.001.mp4           0.476636            0.593407   \n",
       "\n",
       "   ValueConscientiousness  ValueNeurotisicm  ValueOpenness  \\\n",
       "0                0.572816          0.604167       0.611111   \n",
       "1                0.572816          0.604167       0.611111   \n",
       "2                0.572816          0.604167       0.611111   \n",
       "3                0.572816          0.604167       0.611111   \n",
       "4                0.572816          0.604167       0.611111   \n",
       "\n",
       "               ImageName  \n",
       "0  -2qsCrkXdWs.001_1.jpg  \n",
       "1  -2qsCrkXdWs.001_2.jpg  \n",
       "2  -2qsCrkXdWs.001_3.jpg  \n",
       "3  -2qsCrkXdWs.001_4.jpg  \n",
       "4  -2qsCrkXdWs.001_5.jpg  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_output_labels_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Export the output labels dataframe to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_labels_data.to_csv(training_output_labels_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Read the input label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input_labels_data = pd.read_csv(validation_input_labels_path)\n",
    "validation_input_labels_columns = list(validation_input_labels_data.columns.values)\n",
    "validation_input_labels_columns.append(\"ImageName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>ValueExtraversion</th>\n",
       "      <th>ValueAgreeableness</th>\n",
       "      <th>ValueConscientiousness</th>\n",
       "      <th>ValueNeurotisicm</th>\n",
       "      <th>ValueOpenness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DrlC4bEYcmw.001.mp4</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o7rFDFvW300.000.mp4</td>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wx_oe0SxD9w.004.mp4</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4cPiUXpGbc.004.mp4</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yp-tfq1NxBk.005.mp4</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VideoName  ValueExtraversion  ValueAgreeableness  \\\n",
       "0  DrlC4bEYcmw.001.mp4           0.691589            0.615385   \n",
       "1  o7rFDFvW300.000.mp4           0.401869            0.439560   \n",
       "2  Wx_oe0SxD9w.004.mp4           0.485981            0.670330   \n",
       "3  d4cPiUXpGbc.004.mp4           0.523364            0.593407   \n",
       "4  yp-tfq1NxBk.005.mp4           0.532710            0.593407   \n",
       "\n",
       "   ValueConscientiousness  ValueNeurotisicm  ValueOpenness  \n",
       "0                0.524272          0.635417       0.566667  \n",
       "1                0.320388          0.406250       0.555556  \n",
       "2                0.601942          0.625000       0.577778  \n",
       "3                0.543689          0.520833       0.566667  \n",
       "4                0.524272          0.604167       0.666667  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_input_labels_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Create a List for the output label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_output_labels_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Read the contents of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_video_filenames = os.listdir(validation_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Create dataset of images from each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed:  0axZSeaUbfs.003.mp4\n",
      "Failed:  2TXrDZgbDHE.002.mp4\n",
      "Failed:  6M8OQNo64Tc.000.mp4\n",
      "Failed:  CFK8ib0aWe8.004.mp4\n",
      "Failed:  fKrX-KXgXYM.001.mp4\n",
      "Failed:  LRczShwIVbM.002.mp4\n",
      "Failed:  Me22JENkhJA.001.mp4\n",
      "Failed:  p-OcwNFQB0U.003.mp4\n",
      "Failed:  YdxS3f4HXaA.001.mp4\n",
      "Failed:  YdxS3f4HXaA.002.mp4\n"
     ]
    }
   ],
   "source": [
    "n_frames_from_video = 5\n",
    "\n",
    "validation_output_labels_data = getOutputLabels(validation_video_filenames, validation_input_labels_data, \n",
    "                                                validation_video_path, validation_image_path,\n",
    "                                                n_frames_from_video, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Create a DataFrame of the output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_output_labels_data = pd.DataFrame(validation_output_labels_data, columns=validation_input_labels_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoName</th>\n",
       "      <th>ValueExtraversion</th>\n",
       "      <th>ValueAgreeableness</th>\n",
       "      <th>ValueConscientiousness</th>\n",
       "      <th>ValueNeurotisicm</th>\n",
       "      <th>ValueOpenness</th>\n",
       "      <th>ImageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6otZ7M-Mro.003.mp4</td>\n",
       "      <td>0.71028</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-6otZ7M-Mro.003_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6otZ7M-Mro.003.mp4</td>\n",
       "      <td>0.71028</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-6otZ7M-Mro.003_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6otZ7M-Mro.003.mp4</td>\n",
       "      <td>0.71028</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-6otZ7M-Mro.003_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6otZ7M-Mro.003.mp4</td>\n",
       "      <td>0.71028</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-6otZ7M-Mro.003_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6otZ7M-Mro.003.mp4</td>\n",
       "      <td>0.71028</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-6otZ7M-Mro.003_5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VideoName  ValueExtraversion  ValueAgreeableness  \\\n",
       "0  -6otZ7M-Mro.003.mp4            0.71028            0.681319   \n",
       "1  -6otZ7M-Mro.003.mp4            0.71028            0.681319   \n",
       "2  -6otZ7M-Mro.003.mp4            0.71028            0.681319   \n",
       "3  -6otZ7M-Mro.003.mp4            0.71028            0.681319   \n",
       "4  -6otZ7M-Mro.003.mp4            0.71028            0.681319   \n",
       "\n",
       "   ValueConscientiousness  ValueNeurotisicm  ValueOpenness  \\\n",
       "0                0.728155          0.552083       0.666667   \n",
       "1                0.728155          0.552083       0.666667   \n",
       "2                0.728155          0.552083       0.666667   \n",
       "3                0.728155          0.552083       0.666667   \n",
       "4                0.728155          0.552083       0.666667   \n",
       "\n",
       "               ImageName  \n",
       "0  -6otZ7M-Mro.003_1.jpg  \n",
       "1  -6otZ7M-Mro.003_2.jpg  \n",
       "2  -6otZ7M-Mro.003_3.jpg  \n",
       "3  -6otZ7M-Mro.003_4.jpg  \n",
       "4  -6otZ7M-Mro.003_5.jpg  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_output_labels_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation: Export the output labels dataframe to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_output_labels_data.to_csv(validation_output_labels_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Create a List for the output label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_labels_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Read the contents of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_filenames = os.listdir(test_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Create dataset of images from each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_from_video = 5\n",
    "\n",
    "test_output_labels_data = getOutputLabels(test_video_filenames, validation_input_labels_data, \n",
    "                                                test_video_path, test_image_path,\n",
    "                                                n_frames_from_video, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Create a DataFrame of the output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_labels_data = pd.DataFrame(test_output_labels_data, columns=validation_input_labels_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: Export the output labels dataframe to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_labels_data.to_csv(test_output_labels_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
